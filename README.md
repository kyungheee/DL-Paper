# DL-Paper-Implementations# Deep Learning Papers with GitHub Implementations


## Deep Neural Network

| Paper Title | Description | GitHub Link |
|-------------|-------------|-------------|
| [DenseNet: Densely connected convolutional networks](https://arxiv.org/abs/1608.06993) | Densely connected convolutional networks | [GitHub](https://github.com/liuzhuang13/DenseNet) |
| [Wide ResNet: Wide residual networks](https://arxiv.org/abs/1605.07146) | Wide residual networks | [GitHub](https://github.com/szagoruyko/wide-residual-networks) |
| [Highway Networks: Training very deep networks](https://arxiv.org/abs/1505.00387) | Training very deep networks | [GitHub](https://github.com/fchollet/keras/tree/master/examples) |

## Convolutional Neural Network

| Paper Title | Description | GitHub Link |
|-------------|-------------|-------------|
| [AlexNet: Deep learning model for ImageNet classification](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) | Deep learning model for ImageNet classification | [GitHub](https://github.com/kratzert/finetune_alexnet_with_tensorflow) |
| [VGGNet: Very deep convolutional networks](https://arxiv.org/abs/1409.1556) | Very deep convolutional networks | [GitHub](https://github.com/machrisaa/tensorflow-vgg) |
| [ResNet: Deep residual learning framework](https://arxiv.org/abs/1512.03385) | Deep residual learning framework | [GitHub](https://github.com/KaimingHe/deep-residual-networks) |

## Recurrent Neural Network

| Paper Title | Description | GitHub Link |
|-------------|-------------|-------------|
| [LSTM: Long short-term memory](https://www.bioinf.jku.at/publications/older/2604.pdf) | Long short-term memory | [GitHub](https://github.com/farizrahman4u/keras-contrib) |
| [GRU: Gated recurrent unit](https://arxiv.org/abs/1406.1078) | Gated recurrent unit | [GitHub](https://github.com/tensorflow/nmt) |
| [Attention Mechanism: Neural machine translation by jointly learning to align and translate](https://arxiv.org/abs/1409.0473) | Neural machine translation by jointly learning to align and translate | [GitHub](https://github.com/kyubyong/transformer) |

## Attention Mechanism

| Paper Title | Description | GitHub Link |
|-------------|-------------|-------------|
| [Transformer: Attention is all you need](https://arxiv.org/abs/1706.03762) | Attention is all you need | [GitHub](https://github.com/tensorflow/models/tree/master/official/nlp/transformer) |
| [BERT: Pre-training of deep bidirectional transformers for language understanding](https://arxiv.org/abs/1810.04805) | Pre-training of deep bidirectional transformers for language understanding | [GitHub](https://github.com/google-research/bert) |
| [GPT-3: Language models are few-shot learners](https://arxiv.org/abs/2005.14165) | Language models are few-shot learners | [GitHub](https://github.com/openai/gpt-3) |

## Auto-Encoder & VAE

| Paper Title | Description | GitHub Link |
|-------------|-------------|-------------|
| [Variational Autoencoder (VAE): Probabilistic model for generating data](https://arxiv.org/abs/1312.6114) | Probabilistic model for generating data | [GitHub](https://github.com/AntixK/PyTorch-VAE) |
| [Denoising Autoencoder (DAE): Autoencoder for noise reduction](https://www.cs.toronto.edu/~hinton/absps/NC2006.pdf) | Autoencoder for noise reduction | [GitHub](https://github.com/AgustinusKristiadi/denoising-autoencoder) |
| [Sparse Autoencoder: Autoencoder with sparsity constraint](https://cs.stanford.edu/~quocle/LeKarpenkoNgiamCoatesICML2011.pdf) | Autoencoder with sparsity constraint | [GitHub](https://github.com/naokishibuya/deep-learning-zero-to-all) |

## Generative Adversarial Network

| Paper Title | Description | GitHub Link |
|-------------|-------------|-------------|
| [GAN: Generative adversarial networks](https://arxiv.org/abs/1406.2661) | Generative adversarial networks | [GitHub](https://github.com/goodfeli/adversarial) |
| [DCGAN: Deep convolutional GANs](https://arxiv.org/abs/1511.06434) | Deep convolutional GANs | [GitHub](https://github.com/carpedm20/DCGAN-tensorflow) |
| [CycleGAN: Image-to-image translation with GANs](https://arxiv.org/abs/1703.10593) | Image-to-image translation with GANs | [GitHub](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix) |

## Natural Language Processing

| Paper Title | Description | GitHub Link |
|-------------|-------------|-------------|
| [BERT: Transformer-based model for NLP](https://arxiv.org/abs/1810.04805) | Transformer-based model for NLP | [GitHub](https://github.com/google-research/bert) |
| [GPT-3: Generative pre-trained transformer model](https://arxiv.org/abs/2005.14165) | Generative pre-trained transformer model | [GitHub](https://github.com/openai/gpt-3) |
| [Transformer: Attention mechanism for sequence modeling](https://arxiv.org/abs/1706.03762) | Attention mechanism for sequence modeling | [GitHub](https://github.com/tensorflow/models/tree/master/official/nlp/transformer) |

## Graph Neural Network

| Paper Title | Description | GitHub Link |
|-------------|-------------|-------------|
| [GCN: Graph convolutional networks](https://arxiv.org/abs/1609.02907) | Graph convolutional networks | [GitHub](https://github.com/tkipf/gcn) |
| [GraphSAGE: Inductive representation learning on large graphs](https://arxiv.org/abs/1706.02216) | Inductive representation learning on large graphs | [GitHub](https://github.com/williamleif/GraphSAGE) |
| [GAT: Graph attention networks](https://arxiv.org/abs/1710.10903) | Graph attention networks | [GitHub](https://github.com/PetarV-/GAT) |
